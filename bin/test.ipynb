{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2eace19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 17:58:31,589\tERROR tune_controller.py:1383 -- Trial task failed for trial TuneModel_76f62_00002\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/worker.py\", line 2563, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::TuneModel.train()\u001b[39m (pid=58322, ip=10.44.1.111, actor_id=7a19d60d9898f6c32b0c1a0201000000, repr=<src.learner.raytune_learner.TuneModel object at 0x7f3ac830c460>)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 339, in train\n",
      "    result = self.step()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 115, in step\n",
      "    return self.objective()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 121, in objective\n",
      "    return {\"val_loss\": self.compute_validation_loss()}\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 134, in compute_validation_loss\n",
      "    loss += self.model.batch(x, y, optimizer = self.optimizer, **self.loss_dict).item()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/fpkm_model/fpkm_dummy_model.py\", line 44, in batch\n",
      "    loss.backward()\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TuneModel pid=58322)\u001b[0m torch.Size([7, 13780])\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 17:58:32,230\tERROR tune_controller.py:1383 -- Trial task failed for trial TuneModel_76f62_00001\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/worker.py\", line 2563, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::TuneModel.train()\u001b[39m (pid=58321, ip=10.44.1.111, actor_id=110b38b3aff1af874347bb9901000000, repr=<src.learner.raytune_learner.TuneModel object at 0x7f30382f03d0>)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 339, in train\n",
      "    result = self.step()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 115, in step\n",
      "    return self.objective()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 121, in objective\n",
      "    return {\"val_loss\": self.compute_validation_loss()}\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 134, in compute_validation_loss\n",
      "    loss += self.model.batch(x, y, optimizer = self.optimizer, **self.loss_dict).item()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/fpkm_model/fpkm_dummy_model.py\", line 44, in batch\n",
      "    loss.backward()\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "2024-05-06 17:58:32,756\tERROR tune_controller.py:1383 -- Trial task failed for trial TuneModel_76f62_00007\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/worker.py\", line 2563, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::TuneModel.train()\u001b[39m (pid=58327, ip=10.44.1.111, actor_id=29614fe72c5391864635276301000000, repr=<src.learner.raytune_learner.TuneModel object at 0x7f65564284f0>)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 339, in train\n",
      "    result = self.step()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 115, in step\n",
      "    return self.objective()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 121, in objective\n",
      "    return {\"val_loss\": self.compute_validation_loss()}\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 134, in compute_validation_loss\n",
      "    loss += self.model.batch(x, y, optimizer = self.optimizer, **self.loss_dict).item()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/fpkm_model/fpkm_dummy_model.py\", line 44, in batch\n",
      "    loss.backward()\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "2024-05-06 17:58:33,027\tERROR tune_controller.py:1383 -- Trial task failed for trial TuneModel_76f62_00003\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/worker.py\", line 2563, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::TuneModel.train()\u001b[39m (pid=58323, ip=10.44.1.111, actor_id=41188ff89016b779ca3248eb01000000, repr=<src.learner.raytune_learner.TuneModel object at 0x7fc27ad24490>)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 339, in train\n",
      "    result = self.step()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 115, in step\n",
      "    return self.objective()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 121, in objective\n",
      "    return {\"val_loss\": self.compute_validation_loss()}\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 134, in compute_validation_loss\n",
      "    loss += self.model.batch(x, y, optimizer = self.optimizer, **self.loss_dict).item()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/fpkm_model/fpkm_dummy_model.py\", line 44, in batch\n",
      "    loss.backward()\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "2024-05-06 17:58:33,069\tERROR tune_controller.py:1383 -- Trial task failed for trial TuneModel_76f62_00004\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/worker.py\", line 2563, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::TuneModel.train()\u001b[39m (pid=58324, ip=10.44.1.111, actor_id=a4b87a82b387fa111f47e71701000000, repr=<src.learner.raytune_learner.TuneModel object at 0x7f16ed28c400>)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 339, in train\n",
      "    result = self.step()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 115, in step\n",
      "    return self.objective()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 121, in objective\n",
      "    return {\"val_loss\": self.compute_validation_loss()}\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 134, in compute_validation_loss\n",
      "    loss += self.model.batch(x, y, optimizer = self.optimizer, **self.loss_dict).item()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/fpkm_model/fpkm_dummy_model.py\", line 44, in batch\n",
      "    loss.backward()\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "2024-05-06 17:58:33,137\tERROR tune_controller.py:1383 -- Trial task failed for trial TuneModel_76f62_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/worker.py\", line 2563, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::TuneModel.train()\u001b[39m (pid=58320, ip=10.44.1.111, actor_id=0a96f364bf3968a58fdff0db01000000, repr=<src.learner.raytune_learner.TuneModel object at 0x7f6232a00490>)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 339, in train\n",
      "    result = self.step()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 115, in step\n",
      "    return self.objective()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 121, in objective\n",
      "    return {\"val_loss\": self.compute_validation_loss()}\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 134, in compute_validation_loss\n",
      "    loss += self.model.batch(x, y, optimizer = self.optimizer, **self.loss_dict).item()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/fpkm_model/fpkm_dummy_model.py\", line 44, in batch\n",
      "    loss.backward()\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "2024-05-06 17:58:33,523\tERROR tune_controller.py:1383 -- Trial task failed for trial TuneModel_76f62_00006\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/worker.py\", line 2563, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::TuneModel.train()\u001b[39m (pid=58326, ip=10.44.1.111, actor_id=7e83a7552a7ed28d0e62f34601000000, repr=<src.learner.raytune_learner.TuneModel object at 0x7f375e01c400>)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 339, in train\n",
      "    result = self.step()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 115, in step\n",
      "    return self.objective()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 121, in objective\n",
      "    return {\"val_loss\": self.compute_validation_loss()}\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 134, in compute_validation_loss\n",
      "    loss += self.model.batch(x, y, optimizer = self.optimizer, **self.loss_dict).item()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/fpkm_model/fpkm_dummy_model.py\", line 44, in batch\n",
      "    loss.backward()\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "2024-05-06 17:58:38,834\tERROR tune_controller.py:1383 -- Trial task failed for trial TuneModel_76f62_00008\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/worker.py\", line 2563, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::TuneModel.train()\u001b[39m (pid=58796, ip=10.44.1.111, actor_id=220e774bd624c2379d4ae3de01000000, repr=<src.learner.raytune_learner.TuneModel object at 0x7efbaa7ec430>)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 339, in train\n",
      "    result = self.step()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 115, in step\n",
      "    return self.objective()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 121, in objective\n",
      "    return {\"val_loss\": self.compute_validation_loss()}\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 134, in compute_validation_loss\n",
      "    loss += self.model.batch(x, y, optimizer = self.optimizer, **self.loss_dict).item()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/fpkm_model/fpkm_dummy_model.py\", line 44, in batch\n",
      "    loss.backward()\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TuneModel pid=58796)\u001b[0m torch.Size([7, 13780])\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 17:58:39,229\tERROR tune_controller.py:1383 -- Trial task failed for trial TuneModel_76f62_00009\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/_private/worker.py\", line 2563, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::TuneModel.train()\u001b[39m (pid=58828, ip=10.44.1.111, actor_id=405e1213f884bdca1214652701000000, repr=<src.learner.raytune_learner.TuneModel object at 0x7f4b21488490>)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 339, in train\n",
      "    result = self.step()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 115, in step\n",
      "    return self.objective()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 121, in objective\n",
      "    return {\"val_loss\": self.compute_validation_loss()}\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py\", line 134, in compute_validation_loss\n",
      "    loss += self.model.batch(x, y, optimizer = self.optimizer, **self.loss_dict).item()\n",
      "  File \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/fpkm_model/fpkm_dummy_model.py\", line 44, in batch\n",
      "    loss.backward()\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/luisasantus/mambaforge/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "2024-05-06 17:59:56,055\tWARNING tune.py:186 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-05-06 18:00:06,069\tERROR tune.py:1043 -- Trials did not complete: [TuneModel_76f62_00000, TuneModel_76f62_00001, TuneModel_76f62_00002, TuneModel_76f62_00003, TuneModel_76f62_00004, TuneModel_76f62_00006, TuneModel_76f62_00007, TuneModel_76f62_00008, TuneModel_76f62_00009]\n",
      "2024-05-06 18:00:06,070\tINFO tune.py:1047 -- Total run time: 103.65 seconds (93.63 seconds for the tuning loop).\n",
      "2024-05-06 18:00:06,071\tWARNING tune.py:1062 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/home/luisasantus/ray_results/TuneModel_2024-05-06_17-58-22\", trainable=...)\n",
      "2024-05-06 18:00:06,077\tWARNING experiment_analysis.py:185 -- Failed to fetch metrics for 1 trial(s):\n",
      "- TuneModel_76f62_00005: FileNotFoundError('Could not fetch metrics for TuneModel_76f62_00005: both result.json and progress.csv were not found at /home/luisasantus/ray_results/TuneModel_2024-05-06_17-58-22/TuneModel_76f62_00005_5_batch_size=32,loss_fn=CrossEntropyLoss,input_length=2670,kernel_size_1=5,nfilters_conv1=5,method=Adam,lr=0_2024-05-06_17-58-22')\n",
      "2024-05-06 18:00:06,085\tWARNING experiment_analysis.py:575 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No best trial found for the given metric: val_loss. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m learner \u001b[38;5;241m=\u001b[39m StimulusTuneWrapper(config_path, model_class, data_path, initialized_experiment_class)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Tune the model\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# save best config\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#learner.store_best_config(best_config_path)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/bin/src/learner/raytune_learner.py:53\u001b[0m, in \u001b[0;36mTuneWrapper.tune\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03mRun the tuning process.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtuner\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_config \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/ray/tune/result_grid.py:162\u001b[0m, in \u001b[0;36mResultGrid.get_best_result\u001b[0;34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[0m\n\u001b[1;32m    151\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo best trial found for the given metric: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_analysis\u001b[38;5;241m.\u001b[39mdefault_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis means that no trial has reported this metric\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m     )\n\u001b[1;32m    156\u001b[0m     error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, or all values reported for this metric are NaN. To not ignore NaN \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues, you can set the `filter_nan_and_inf` arg to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filter_nan_and_inf\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(error_msg)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trial_to_result(best_trial)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No best trial found for the given metric: val_loss. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import importlib.util\n",
    "\n",
    "from src.learner.raytune_learner import TuneWrapper as StimulusTuneWrapper\n",
    "from launch_utils import import_class_from_file, get_experiment\n",
    "from src.utils.yaml_model_schema import YamlRayConfigLoader\n",
    "\n",
    "\n",
    "model_path = \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/fpkm_model/fpkm_dummy_model.py\"\n",
    "json_experiment = \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/fpkm_model/fpkm_pipelinegenerated.json\"\n",
    "config_path = \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/fpkm_model/fpkm_dummy_model.yaml\"\n",
    "data_path = \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/work/9d/0ebf1c448bbe1a0ca653b26bea66f7/test-fpkm-#2-trans.csv\"\n",
    "best_config_path = \"/home/luisasantus/Desktop/crg_cluster/projects/crossevo_stimulus/stimulus/fpkm_model/best_config.json\"\n",
    "\n",
    "# import the model correctly but do not initialize it yet, ray_tune does that itself\n",
    "model_class = import_class_from_file(model_path)\n",
    "\n",
    "# read json and retrieve experiment name and then initialize the experiment class\n",
    "experiment_name = None\n",
    "with open(json_experiment, 'r') as in_json:\n",
    "    d = json.load(in_json)\n",
    "    experiment_name = d[\"experiment\"]\n",
    "initialized_experiment_class = get_experiment(experiment_name)\n",
    "\n",
    "# Create the learner\n",
    "learner = StimulusTuneWrapper(config_path, model_class, data_path, initialized_experiment_class)\n",
    "\n",
    "\n",
    "# Tune the model\n",
    "learner.tune()\n",
    "# save best config\n",
    "#learner.store_best_config(best_config_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11fce422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ray.tune.tuner.Tuner at 0x7f9f03f20bb0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner = learner.tuner\n",
    "tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1431ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfd3b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9611d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2257bf49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c416a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9cb3457e621fef10ccc726cdf49c3a6d7ae9ec7c3c7d02b1814e28a4a388400d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
